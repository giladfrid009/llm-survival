{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from src.rating.base import *\n",
    "from src.generation.base import *\n",
    "import torch\n",
    "\n",
    "utils.set_seed(42)\n",
    "utils.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/allenai/real-toxicity-prompts/prompts.jsonl\", lines=True)\n",
    "\n",
    "input_dicts = df[\"prompt\"].values.flatten().tolist()\n",
    "\n",
    "inputs = [d[\"text\"] for d in input_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_key = utils.api_key_from_file(\"HF_KEY.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rating.detoxify import DetoxifyRater\n",
    "\n",
    "rater_backend = DetoxifyRater(\n",
    "    model_type=\"original\",\n",
    "    amp=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.rating.llama_guard import LlamaGuardRater\n",
    "# import torch\n",
    "\n",
    "# rater_backend = LlamaGuardRater(\n",
    "#     model_name=\"meta-llama/Llama-Guard-3-1B\",\n",
    "#     hub_token=hf_key,\n",
    "#     max_input_tokens=100,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.vanilla_model import VanillaGenerator\n",
    "\n",
    "generator_backend = VanillaGenerator(\n",
    "    model_name=\"meta-llama/Llama-3.2-1B\",\n",
    "    hub_token=hf_key,\n",
    "    max_input_tokens=40,\n",
    "    max_output_tokens=30,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.generation.chat_model import ChatGenerator\n",
    "\n",
    "# generator_backend = ChatGenerator(\n",
    "#     model_name=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "#     hub_token=hf_key,\n",
    "#     max_input_tokens=40,\n",
    "#     max_output_tokens=30,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create survival analysis runner\n",
    "\n",
    "from functools import partial\n",
    "from src.survival_runner import (\n",
    "    SurvivalRunner,\n",
    "    SurvivalResult,\n",
    "    default_toxicity_func,\n",
    "    default_text_prep_func,\n",
    ")\n",
    "\n",
    "batch_size = 3500\n",
    "max_attempts = 40\n",
    "\n",
    "survival_runner = SurvivalRunner(\n",
    "    generator=generator_backend,\n",
    "    rater=rater_backend,\n",
    "    max_attempts=max_attempts,\n",
    "    toxicity_func=partial(default_toxicity_func, thresh=0.1),\n",
    "    text_prep_func=lambda gen: gen.prompt + gen.output,\n",
    "    conserve_memory=True,\n",
    ")\n",
    "\n",
    "survival_results = survival_runner.generate(\n",
    "    prompts=inputs,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run survival analysis and print results\n",
    "\n",
    "survival_list: list[SurvivalResult] = []\n",
    "for res in survival_results:\n",
    "    survival_list.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display histogram of survival times\n",
    "survival_time = [r.num_attempts for r in survival_list]\n",
    "counts, edges, bars = plt.hist(survival_time, bins=20)\n",
    "plt.bar_label(bars)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-surv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
