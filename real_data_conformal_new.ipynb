{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lightning model from checkpoint\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader  # Import DataLoader\n",
    "from src.failure_model import ToxicClassifier\n",
    "from src.datasets import PromptOnlyDataset, PropDataset\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "try:\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_prompts = PromptOnlyDataset(\"data/rtp_500/split_1_0.5_0.1_0.2_0.2/cal.pkl\")\n",
    "cal_props = PropDataset(\"data/rtp_500/split_1_0.5_0.1_0.2_0.2/cal.pkl\", score_name=\"toxicity\", threshold=0.5)\n",
    "\n",
    "cal_prompts.data = cal_prompts.data[-10000:]\n",
    "cal_props.data = cal_props.data[-10000:]\n",
    "\n",
    "model = ToxicClassifier.load_from_checkpoint(\"saved/Jigsaw_BERT/lightning_logs/version_0/checkpoints/epoch=7-step=1552.ckpt\")\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = torch.tensor(np.logspace(-3, 0, 200))\n",
    "\n",
    "# Get the index closest to 0.1\n",
    "idx = (taus - 0.1).abs().argmin()\n",
    "\n",
    "model.set_taus(taus)\n",
    "\n",
    "model.set_min_p_for_q_tau(1 / 500)\n",
    "# model.set_min_p_for_q_tau(1e-20)\n",
    "# model.set_threshold_p_for_q_tau(1e-4)\n",
    "\n",
    "trainer = pl.Trainer()\n",
    "\n",
    "# Create a custom DataLoader for prediction with a batch size of 1500\n",
    "predict_dataloader = DataLoader(cal_prompts, batch_size=1500, shuffle=False)\n",
    "\n",
    "# Use the trainer and predict on cal_prompts using the custom DataLoader\n",
    "raw_pred = trainer.predict(model, dataloaders=predict_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = {\n",
    "    \"proba\": torch.cat([p[\"proba\"] for p in raw_pred], dim=0),\n",
    "}\n",
    "if \"tau\" in raw_pred[0]:\n",
    "    pred[\"tau\"] = torch.cat([p[\"tau\"] for p in raw_pred], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "emp_probs = [item[1][0] for item in cal_props]\n",
    "emp_probs = torch.tensor(emp_probs, dtype=torch.float32).flatten()\n",
    "pred_probs = torch.tensor(pred[\"proba\"], dtype=torch.float32).flatten()\n",
    "\n",
    "# emp_probs = torch.permute(emp_probs, dims=[0])\n",
    "# pred_probs = torch.permute(pred_probs, dims=[0])\n",
    "\n",
    "mse_val = torch.nn.functional.mse_loss(emp_probs, pred_probs)\n",
    "print(f\"Mean Squared Error: {mse_val.item()}\")\n",
    "\n",
    "ce_val = torch.nn.functional.binary_cross_entropy(pred_probs, emp_probs)\n",
    "print(f\"Binary Cross Entropy: {ce_val.item()}\")\n",
    "\n",
    "mae_val = torch.nn.functional.l1_loss(emp_probs, pred_probs)\n",
    "print(f\"Mean Absolute Error: {mae_val.item()}\")\n",
    "\n",
    "# plot histogram of pred_probs\n",
    "# plot histogram of emp_probs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pred_probs.numpy(), bins=50, alpha=0.5, label='pred_probs')\n",
    "plt.hist(emp_probs.numpy(), bins=50, alpha=0.5, label='emp_probs')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of pred_probs and emp_probs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# compute 0.1 quantile of Geom(emp_probs) and Geom(pred_probs) \n",
    "\n",
    "eps = 1/500\n",
    "quant_value = 0.1\n",
    "pred_probs_clamp = torch.clamp(pred_probs, min=eps, max=1)\n",
    "emp_probs_clamp = torch.clamp(emp_probs, min=eps, max=1)\n",
    "\n",
    "quant_emp = torch.ceil(math.log(1 - 0.1) / torch.log(1 - emp_probs_clamp)).clamp(min=1)\n",
    "quant_pred = torch.ceil(math.log(1 - quant_value) / torch.log(1 - pred_probs_clamp)).clamp(min=1)\n",
    "\n",
    "# print histogram of quant_emp and quant_pred\n",
    "plt.hist(quant_emp.numpy(), bins=50, alpha=0.5, label='quant_emp')\n",
    "plt.hist(quant_pred.numpy(), bins=50, alpha=0.5, label='quant_pred')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Histogram of quant_emp and quant_pred ; q={quant_value}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Min pred_probs: {pred_probs.min().item()}\")\n",
    "print(f\"Max pred_probs: {pred_probs.max().item()}\")\n",
    "print(f\"Min emp_probs: {emp_probs.min().item()}\")\n",
    "print(f\"Max emp_probs: {emp_probs.max().item()}\")\n",
    "\n",
    "# compute coverage of emp_probs by pred_probs\n",
    "coverage_orig = torch.mean((pred_probs >= emp_probs).float())\n",
    "print(f\"Probability Coverage of prob_emp by prob_pred: {coverage_orig.item()}\")\n",
    "\n",
    "coverate_clamp = torch.mean((quant_pred <= quant_emp).float())\n",
    "print(f\"Quantile Coverage of quant_emp by quant_pred: {coverate_clamp.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Geometric\n",
    "\n",
    "# plot histogram of Geom(pred_probs)\n",
    "# and of predicted quantiles\n",
    "\n",
    "time_emp = Geometric(emp_probs_clamp).sample().clamp(min=1)\n",
    "\n",
    "quant_value = 0.1\n",
    "quant_pred = torch.ceil(math.log(1 - quant_value) / torch.log(1 - pred_probs_clamp)).clamp(min=1)\n",
    "\n",
    "print(\"Avg LPB: \", quant_pred.mean().item())\n",
    "\n",
    "# print histogram of quant_emp and quant_pred\n",
    "plt.hist([time_emp.numpy(), quant_pred.numpy()], bins=50, label=['T_tilde', 'quant_pred'])\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Histogram of Sampled Times and quant_pred')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "coverage = torch.mean((quant_pred <= time_emp).float())\n",
    "print(f\"Coverage of time_emp by quant_pred: {coverage.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# from scipy.stats.geom import ppf\n",
    "import scipy\n",
    "\n",
    "# TODO: UNDERSTAND WHY PPF DOESNT MATCH\n",
    "\n",
    "quant_pred = [scipy.stats.geom.ppf(taus[idx], min(max(item.item(), eps), 1)) for item in pred['proba']]\n",
    "\n",
    "quant_emp = [scipy.stats.geom.ppf(taus[idx], min(max(item[1][0], eps), 1)) for item in cal_props]\n",
    "\n",
    "\n",
    "plt.hist(quant_emp, bins=50, alpha=0.5, label='quant_emp')\n",
    "plt.hist(quant_pred, bins=50, alpha=0.5, label='quant_pred')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of quant_emp and quant_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
