{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "utils.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/0124/toxic-chat_annotation_train.csv', 'test': 'data/0124/toxic-chat_annotation_test.csv'}\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/lmsys/toxic-chat/\" + splits[\"train\"])\n",
    "\n",
    "inputs = df[\"user_input\"].values.flatten().tolist()\n",
    "\n",
    "toxic_input = df[\"toxicity\"]\n",
    "\n",
    "inputs = [input_prompt for input_prompt, toxic in zip(inputs, toxic_input) if toxic == 1]\n",
    "\n",
    "# input_dicts = df[\"user_input\"].values.flatten().tolist()\n",
    "\n",
    "# inputs = [d[\"text\"] for d in input_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Create the figure and axes for two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Compute word counts using nltk's word_tokenize\n",
    "word_counts = [len(word_tokenize(text)) for text in tqdm(inputs, desc=\"Word Tokenization\")]\n",
    "\n",
    "# Plot histogram for word counts\n",
    "ax0 = axes[0]\n",
    "ax0.hist(word_counts, bins=range(min(word_counts), max(word_counts) + 2), edgecolor=\"black\")\n",
    "ax0.set_title(\"Number of Words\")\n",
    "ax0.set_xlabel(\"Word Count\")\n",
    "ax0.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Load the tokenizer and compute token counts\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_counts = [len(tokenizer.tokenize(text)) for text in tqdm(inputs, desc=\"Tokenization\")]\n",
    "\n",
    "# Plot histogram for token counts\n",
    "ax1 = axes[1]\n",
    "ax1.hist(token_counts, bins=range(min(token_counts), max(token_counts) + 2), edgecolor=\"black\")\n",
    "ax1.set_title(\"Number of Tokens\")\n",
    "ax1.set_xlabel(\"Token Count\")\n",
    "ax1.set_ylabel(\"Frequency\")\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from src.rating.llama_guard import LlamaGuardRater\n",
    "\n",
    "# # TODO: MODIFYING BATCH-SIZE FROM 1 TO 50 CHANGES THE RESULTS \\\n",
    "# # IN THE FOLLOWING CELL SLIGHTLY. INVESTIGATE WHY. \n",
    "# hf_key = utils.api_key_from_file(\"HF_KEY.txt\")\n",
    "# rater_backend = LlamaGuardRater(\n",
    "#     model_name=\"meta-llama/Llama-Guard-3-1B\",\n",
    "#     hub_token=hf_key,\n",
    "#     max_input_tokens=100,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rating.detoxify import DetoxifyRater\n",
    "\n",
    "rater_backend = DetoxifyRater(model_type=\"unbiased\", amp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rating.base import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rating_runner = RatingRunner(rater_backend)\n",
    "rating_results = rating_runner.rate_stram(inputs[-200:], batch_size=50)\n",
    "rating_results = list(rating_results)\n",
    "\n",
    "toxicity_scores = [r.scores[\"toxicity\"] for r in rating_results]\n",
    "counts, edges, bars = plt.hist(toxicity_scores, bins=20)\n",
    "plt.bar_label(bars)\n",
    "plt.show()\n",
    "\n",
    "# Print examples of toxicity > 0.5 and < 0.5\n",
    "toxic_examples = [r for r in rating_results if r.scores[\"toxicity\"] > 0.5]\n",
    "non_toxic_examples = [r for r in rating_results if r.scores[\"toxicity\"] <= 0.5]\n",
    "\n",
    "print(\"TOXIC EXAMPLES:\")\n",
    "for r in toxic_examples[:10]:\n",
    "    print(r.text)\n",
    "\n",
    "print()\n",
    "print(\"NON-TOXIC EXAMPLES:\")\n",
    "for r in non_toxic_examples[:10]:\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "text = \"What is the capital of France? The capital of France is Paris. What is the capital of Italy? The capital of Italy is Rome.\"\n",
    "split_text = sent_tokenize(text)\n",
    "print(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.chat_model import ChatGenerator\n",
    "from src.generation.vanilla_model import VanillaGenerator\n",
    "\n",
    "hf_key = utils.api_key_from_file(\"HF_KEY.txt\")\n",
    "generator_backend = ChatGenerator(\n",
    "    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    hub_token=hf_key,\n",
    "    max_input_tokens=100,\n",
    "    # max_output_tokens=30,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CompileConfig\n",
    "from src.generation.base import GenerationRunner\n",
    "\n",
    "generation_runner = GenerationRunner(generator_backend)\n",
    "generated_texts = generation_runner.generate_stream(\n",
    "    inputs[:5000],\n",
    "    batch_size=300,\n",
    "    # padding=\"max_length\",\n",
    "    # cache_implementation=\"static\",\n",
    "    # compile_config=CompileConfig(\n",
    "    #     fullgraph=True,\n",
    "    #     dynamic=True,\n",
    "    #     backend=\"inductor\",\n",
    "    #     mode=\"reduce-overhead\",\n",
    "    # ),\n",
    ")\n",
    "\n",
    "# generated_list = list(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample 10 random examples\n",
    "\n",
    "# import random\n",
    "\n",
    "# random.seed(42)\n",
    "# random_examples = random.sample(generated_list, 10)\n",
    "\n",
    "# for example in random_examples:\n",
    "#     print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from src.survival_runner import (\n",
    "    SurvivalRunner,\n",
    "    SurvivalResult,\n",
    "    default_toxicity_func,\n",
    "    default_text_prep_func,\n",
    ")\n",
    "\n",
    "survival_runner = SurvivalRunner(\n",
    "    generator=generator_backend,\n",
    "    rater=rater_backend,\n",
    "    max_attempts=100,\n",
    "    toxicity_func=partial(default_toxicity_func, thresh=0.1),\n",
    "    # text_prep_func=lambda gen: gen.prompt + gen.output,\n",
    "    text_prep_func=default_text_prep_func,\n",
    "    conserve_memory=False,\n",
    ")\n",
    "\n",
    "survival_results = survival_runner.generate(\n",
    "    prompts=inputs[:],\n",
    "    batch_size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_list: list[SurvivalResult] = []\n",
    "for res in survival_results:\n",
    "    survival_list.append(res)\n",
    "    print(f\"After {res.num_attempts} attempts, prompt {res.prompt} got {res.ratings[-1].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "survival_time = [r.num_attempts for r in survival_list]\n",
    "_ = plt.hist(survival_time, bins=20)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Amount of prompts that broke before 10 attempts: {len([r for r in survival_list if r.num_attempts < 10])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
