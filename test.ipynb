{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "df = pd.read_json(\"hf://datasets/allenai/real-toxicity-prompts/prompts.jsonl\", lines=True)\n",
                "\n",
                "input_dicts = df[\"prompt\"].values.flatten().tolist()\n",
                "\n",
                "inputs = [d[\"text\"] for d in input_dicts]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from src.perspective.backend import PerspectiveBackend\n",
                "# from src.perspective.utils import api_key_from_env, api_key_from_file\n",
                "\n",
                "# api_key = api_key_from_file(\"PERSPECTIVE_API_KEY.txt\")\n",
                "# backend = PerspectiveBackend(api_key=api_key, rate_limit=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.detoxify.backend import DetoxifyBackend\n",
                "\n",
                "backend = DetoxifyBackend(model_type=\"original\", amp=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.rating import *\n",
                "\n",
                "rating_runner = RatingRunner(backend)\n",
                "results = rating_runner.rate_stram(inputs[-200:], batch_size=100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_list = list(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "toxicity_scores = [r.scores[\"toxicity\"] for r in results_list]\n",
                "\n",
                "# Plot the distribution of toxicity scores\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.hist(toxicity_scores, bins=20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print examples of toxicity > 0.5 and < 0.5\n",
                "toxic_examples = [r for r in results_list if r.scores[\"toxicity\"] > 0.5]\n",
                "non_toxic_examples = [r for r in results_list if r.scores[\"toxicity\"] <= 0.5]\n",
                "\n",
                "print(\"Toxic examples:\")\n",
                "for r in toxic_examples[:5]:\n",
                "    print(r.text)\n",
                "\n",
                "print(\"Non-toxic examples:\")\n",
                "for r in non_toxic_examples[:5]:\n",
                "    print(r.text)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "dc0fc2d6827e46a98e3ebf1328e50ac4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from src.hf_auto_model.backend import AutoModelBackend\n",
                "from huggingface_hub import login\n",
                "from src.perspective.utils import api_key_from_file\n",
                "\n",
                "hf_key = api_key_from_file(\"HF_KEY.txt\")\n",
                "login(token=hf_key)\n",
                "\n",
                "backend = AutoModelBackend()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from src.generation import GenerationRunner\n",
                "\n",
                "generation_runner = GenerationRunner(backend)\n",
                "generated_texts = generation_runner.generate_stream(inputs[:10])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "generated_list = list(generated_texts)\n",
                "\n",
                "# Print the generated texts as well as the input prompts\n",
                "for generated_text in generated_list:\n",
                "    if not generated_text.error:\n",
                "        print(\"Input prompt:\")\n",
                "        print(generated_text.prompt)\n",
                "        print(\"Generated text:\")\n",
                "        print(generated_text.outputs)\n",
                "        print()\n",
                "    else:\n",
                "        print(\"Error:\", generated_text.error)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[' Please do not submit it as a real answer.\\n\\n## Step 1: Understand the task\\nThe task is to provide a solution to a problem that does not exist yet.\\n\\n## Step 2: Determine the problem\\nSince the problem does not exist']\n"
                    ]
                }
            ],
            "source": [
                "generated_text = generation_runner.generate_single(\"This is a test prompt.\")\n",
                "\n",
                "print(generated_text.outputs)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "llm-survival",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
