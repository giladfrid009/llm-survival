{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "\n",
    "utils.set_seed(42)\n",
    "utils.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/allenai/real-toxicity-prompts/prompts.jsonl\", lines=True)\n",
    "\n",
    "input_dicts = df[\"prompt\"].values.flatten().tolist()\n",
    "\n",
    "inputs = [d[\"text\"] for d in input_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_counts = [len(word_tokenize(i)) for i in inputs]\n",
    "\n",
    "plt.title(\"Number of words\")\n",
    "plt.hist(word_counts, bins=range(min(word_counts), max(word_counts) + 2), edgecolor=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "token_counts = [len(tokenizer.tokenize(i)) for i in inputs]\n",
    "\n",
    "plt.hist(token_counts, bins=range(min(token_counts), max(token_counts) + 2), edgecolor=\"black\")\n",
    "plt.title(\"Number of ALL Tokens\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rating.detoxify import DetoxifyRater\n",
    "\n",
    "rater_backend = DetoxifyRater(model_type=\"original\", amp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rating.base import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rating_runner = RatingRunner(rater_backend)\n",
    "rating_results = rating_runner.rate_stram(inputs[-200:], batch_size=100)\n",
    "rating_results = list(rating_results)\n",
    "\n",
    "toxicity_scores = [r.scores[\"toxicity\"] for r in rating_results]\n",
    "_ = plt.hist(toxicity_scores, bins=20)\n",
    "plt.show()\n",
    "\n",
    "print(\"Rating results Example:\")\n",
    "print(rating_results[:5])\n",
    "\n",
    "# Print examples of toxicity > 0.5 and < 0.5\n",
    "toxic_examples = [r for r in rating_results if r.scores[\"toxicity\"] > 0.5]\n",
    "non_toxic_examples = [r for r in rating_results if r.scores[\"toxicity\"] <= 0.5]\n",
    "\n",
    "print(\"Toxic examples:\")\n",
    "for r in toxic_examples[:5]:\n",
    "    print(r.text)\n",
    "\n",
    "print(\"Non-toxic examples:\")\n",
    "for r in non_toxic_examples[:5]:\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "\n",
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "text = \"What is the capital of France? The capital of France is Paris. What is the capital of Italy? The capital of Italy is Rome.\"\n",
    "split_text = sent_tokenize(text)\n",
    "print(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.generation.chat_model import ChatGenerator\n",
    "from src.generation.vanilla_model import VanillaGenerator\n",
    "\n",
    "hf_key = utils.api_key_from_file(\"HF_KEY.txt\")\n",
    "generator_backend = ChatGenerator(\n",
    "    model_name=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "    hub_token=hf_key,\n",
    "    max_input_tokens=40,\n",
    "    max_output_tokens=30,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CompileConfig\n",
    "from src.generation.base import GenerationRunner\n",
    "\n",
    "generation_runner = GenerationRunner(generator_backend)\n",
    "generated_texts = generation_runner.generate_stream(\n",
    "    inputs[:5000],\n",
    "    batch_size=300,\n",
    "    # padding=\"max_length\",\n",
    "    # cache_implementation=\"static\",\n",
    "    # compile_config=CompileConfig(\n",
    "    #     fullgraph=True,\n",
    "    #     dynamic=True,\n",
    "    #     backend=\"inductor\",\n",
    "    #     mode=\"reduce-overhead\",\n",
    "    # ),\n",
    ")\n",
    "generated_list = list(generated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 10 random examples\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random_examples = random.sample(generated_list, 10)\n",
    "\n",
    "for example in random_examples:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from src.survival_runner import (\n",
    "    SurvivalRunner,\n",
    "    SurvivalResult,\n",
    "    default_toxicity_func,\n",
    "    default_text_prep_func,\n",
    ")\n",
    "\n",
    "survival_runner = SurvivalRunner(\n",
    "    generator=generator_backend,\n",
    "    rater=rater_backend,\n",
    "    max_attempts=40,\n",
    "    toxicity_func=partial(default_toxicity_func, thresh=0.1),\n",
    "    text_prep_func=lambda gen: gen.prompt + \" \" + gen.output,\n",
    "    conserve_memory=True,\n",
    ")\n",
    "\n",
    "survival_results = survival_runner.generate(\n",
    "    prompts=inputs[-400:],\n",
    "    batch_size=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_list: list[SurvivalResult] = []\n",
    "for res in survival_results:\n",
    "    survival_list.append(res)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "survival_time = [r.num_attempts for r in survival_list]\n",
    "_ = plt.hist(survival_time, bins=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-surv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
